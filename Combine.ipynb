{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from keras_facenet import FaceNet\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "facenet_model = FaceNet()\n",
    "detector = cv2.CascadeClassifier('./Dataset/haar.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder ,Normalizer\n",
    "\n",
    "data = np.load('./Face_npz/FaceEmbedHarr.npz')\n",
    "\n",
    "in_coder = Normalizer()\n",
    "out_coder = LabelEncoder()\n",
    "\n",
    "emd_trainX,trainy,emd_testX,testy = data['arr_0'],data['arr_1'],data['arr_2'],data['arr_3']\n",
    "\n",
    "# Normalizer\n",
    "emd_trainX_norm = in_coder.fit_transform(emd_trainX)\n",
    "emd_testX_norm = in_coder.transform(emd_testX)\n",
    "\n",
    "# FIT\n",
    "out_coder.fit(trainy)\n",
    "trainy_enc = out_coder.transform(trainy)\n",
    "testy_enc = out_coder.transform(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(filename,resize=(160,160)):\n",
    "    try:\n",
    "        img = cv2.imread(filename)\n",
    "        if img is None:\n",
    "            print(f'Fail to load image from {filename}')\n",
    "            return None\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    except Exception as e:\n",
    "        print(f'While error processing {filename} : {str(e)}')\n",
    "        return None\n",
    "    faces = detector.detectMultiScale(gray_img,1.1,5)\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    x,y,w,h = faces[0]\n",
    "    face = img[y:y+h,x:x+w]\n",
    "    img_face = Image.fromarray(cv2.cvtColor(face,cv2.COLOR_BGR2RGB))\n",
    "    img_face = img_face.resize(resize)\n",
    "    face_arr = np.asarray(img_face)\n",
    "    return face_arr\n",
    "\n",
    "def get_embedding(facenet_model , face):\n",
    "    face_pixel = face.astype('float32')\n",
    "    samples =  np.expand_dims(face_pixel,axis=0)\n",
    "    embed = facenet_model.embeddings(samples)\n",
    "    return embed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_face = pickle.load(open('./Dataset/model.p','rb'))\n",
    "model_recommend = Word2Vec.load('./Dataset/amazon_store.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(face):\n",
    "    img = extract_face(face)\n",
    "    embed = get_embedding(facenet_model,img)\n",
    "    embed = np.expand_dims(embed,axis=0)\n",
    "    embed_norm = in_coder.transform(embed)\n",
    "    index = model_face.predict(embed_norm)\n",
    "    proba = model_face.predict_proba(embed_norm)\n",
    "    class_prob = proba[0,index[0]]\n",
    "    predict_names = out_coder.inverse_transform(index)\n",
    "    return predict_names[0], class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 172ms/step\n"
     ]
    }
   ],
   "source": [
    "#filenames = './Image/10_classes/Alex/alex.jpg'\n",
    "#names, prob  = prediction(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = pickle.load(open('./Dataset/Database.pkl','rb'))\n",
    "dataset_amazon = pd.read_csv('./Dataset/dataset_amazom.csv')\n",
    "dataset_amazon['Customer ID'] = dataset_amazon['Customer ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2216\\4148856084.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  products.drop_duplicates(inplace =True, subset='StockCode',keep='last')\n"
     ]
    }
   ],
   "source": [
    "products = dataset_amazon[['StockCode','Description']]\n",
    "\n",
    "products.drop_duplicates(inplace =True, subset='StockCode',keep='last')\n",
    "products_dict = products.groupby('StockCode')['Description'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(products_dict,open('product_dict.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reccomend_retail(filename):\n",
    "    product_rec = []\n",
    "    try:\n",
    "        predict_names = prediction(filename)\n",
    "        check_id = database[database['Names'] == predict_names]['Customer ID'].values[0]\n",
    "        sku = dataset_amazon[dataset_amazon['Customer ID'] == check_id]['StockCode'].values[:5]\n",
    "        print('Hi... {}'.format(predict_names))\n",
    "        for i in range(len(sku)):\n",
    "            try:\n",
    "                similars = model_recommend.wv.most_similar(sku[i], topn=5)\n",
    "                for j in similars:\n",
    "                    if j[1] > 0.5:\n",
    "                        product_rec.append(products_dict[j[0]][0])\n",
    "            except KeyError:\n",
    "                # Handle the KeyError here, e.g., you can print a message or simply continue the loop.\n",
    "                print(f\"KeyError for SKU: {sku[i]}. Skipping...\")\n",
    "                continue\n",
    "    except AttributeError as e:\n",
    "        print('Sorry Can not detect face')\n",
    "        return product_rec\n",
    "    return product_rec,sku\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face2(img,re_size=(160,160)):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    faces = detector.detectMultiScale(gray_img,1.1,5)\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    x,y,w,h = faces[0]\n",
    "    face = img[y:y+h,x:x+w]\n",
    "    img_face = Image.fromarray(cv2.cvtColor(face,cv2.COLOR_BGR2RGB))\n",
    "    img = img_face.resize(re_size)\n",
    "    face_arr = np.asarray(img)\n",
    "    return face_arr\n",
    "\n",
    "def get_embedding2(facenet_model, face):\n",
    "    if face is None:\n",
    "        return None\n",
    "    \n",
    "    face_pixel = face.astype('float32')\n",
    "    samples = np.expand_dims(face_pixel, axis=0)\n",
    "    embedd = facenet_model.embeddings(samples)\n",
    "    return embedd[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "Conf: 0.5028037041886183\n",
      "Hi... Alex\n",
      "['GREEN CHRISTMAS TREE STRING 20LIGHT', 'WHITE BEADED GARLAND STRING 20LIGHT', 'RED REINDEER STRING OF 20 LIGHTS', 'HOLLY TOP CHRISTMAS STOCKING', 'TRADITIONAL CHRISTMAS RIBBONS', 'WHITE CHERRY LIGHTS', 'LIGHT PINK CHERRY LIGHTS', 'GREEN CHERRY LIGHTS', 'SILVER CHERRY LIGHTS', 'GOLD  CHERRY LIGHTS', 'PINK CHERRY LIGHTS', 'LIGHT PINK CHERRY LIGHTS', 'GREEN CHERRY LIGHTS', 'SILVER CHERRY LIGHTS', 'GOLD  CHERRY LIGHTS', 'VINTAGE CARAVAN GREETING CARD ', 'BLACK RECORD COVER FRAME', 'PINK DOUGHNUT TRINKET POT ', 'ROBOT BIRTHDAY CARD', 'TEA PARTY BIRTHDAY CARD', 'SWEETHEART CERAMIC TRINKET BOX', 'CHOC TRUFFLE GOLD TRINKET POT ', 'PINK DOUGHNUT TRINKET POT ', 'RED SPOTTY BISCUIT TIN', 'CERAMIC STRAWBERRY DESIGN MUG']\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "names_product = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        face = extract_face2(frame)\n",
    "        face_embed = get_embedding2(facenet_model, face)\n",
    "        cv2.imshow('output', frame)\n",
    "        if face_embed is not None:\n",
    "            samples = np.expand_dims(face_embed,axis=0)\n",
    "            index = model_face.predict(samples)\n",
    "            proba = model_face.predict_proba(samples)\n",
    "            class_prob = proba[0,index[0]]\n",
    "            if class_prob >= 0.5:\n",
    "                print('Conf: {}'.format(class_prob))\n",
    "                predict_names = out_coder.inverse_transform(index)\n",
    "                check_id = database[database['Names']== predict_names[0]]['Customer ID'].values[0]\n",
    "                sku = dataset_amazon[dataset_amazon['Customer ID']==check_id]['StockCode'].values[:5]\n",
    "                print('Hi... {}'.format(predict_names[0]))\n",
    "                for i in range(len(sku)):\n",
    "                    try:\n",
    "                        similars = model_recommend.wv.most_similar(sku[i],topn=5)\n",
    "                        for j in similars:\n",
    "                            if j[1] > 0.6:\n",
    "                            #print('{:6} {:36} {:.3f}'.format(j[0],products_dict[j[0]][0],j[1]))\n",
    "                                names_product.append(products_dict[j[0]][0])\n",
    "                    except KeyError:\n",
    "                        # Handle the KeyError here, e.g., you can print a message or simply continue the loop.\n",
    "                        print(f\"KeyError for SKU: {sku[i]}. Skipping...\")\n",
    "                        continue    \n",
    "                break\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('d'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(names_product)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
